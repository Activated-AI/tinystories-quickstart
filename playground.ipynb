{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import GPTConfig, GPT, generate\n",
    "import torch\n",
    "import tokenizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12l_16h_512d_8k_vocab_2e3_lr_good_max_more_warmup  0.374 step 9681 | val loss 1.5355 | byte loss 0.3736 | ds 600.5s\n",
      "10l_16h_512d_8k_vocab                              0.377 step 11500 | val loss 1.5478 | byte loss 0.3766 | ds 594.2s\n",
      "12l_16h_512d_8k_vocab                              0.378 step 9881 | val loss 1.5521 | byte loss 0.3776 | ds 600.7s\n",
      "16l_12h_384d_8k_vocab_2e3_lr_good_max_beta_hax     0.381 step 9349 | val loss 1.5660 | byte loss 0.3810 | ds 589.1s\n",
      "10l_16h_512d_4k_vocab                              0.382 step 11500 | val loss 1.5065 | byte loss 0.3816 ds 593.7s\n",
      "12l_32h_512d_8k_vocab_2e3_lr_good_max_eos          0.382 step 7891 | val loss 1.5621 | byte loss 0.3819 | ds 601.0s\n",
      "10l_12h_384d_more_lr_less_decay                    0.384 step 13999 | val loss 1.5789 | byte loss 0.3841 ds 555.5s\n",
      "16l_12h_384d_8k_vocab_2e3_lr_bad_max               0.388 step 9311 | val loss 1.5942 | byte loss 0.3879 | ds 600.9s\n",
      "12l_12h_384d_less_feedfoward_more_lr               0.391 step 12250 | val loss 1.6070 | byte loss 0.3910 ds 568.6s\n",
      "basic_8_256                                        0.394 step 16250 | val loss 1.6190 | byte loss 0.3939 ds 594.2s\n",
      "8_256_less_feedfoward_more_layers                  0.4 step 13250 | val loss 1.6447 | byte loss 0.4002 ds 582.9s\n",
      "16_256_more_feedfoward                             0.401 step 12250 | val loss 1.6466 | byte loss 0.4006 ds 566.5s\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for i in os.listdir('logs'):\n",
    "    if 'smoke' in i:\n",
    "        continue\n",
    "    best_loss_for_i = 10000\n",
    "    best_line = ''\n",
    "    for line in open('logs/'+i+'/log.txt').readlines():\n",
    "\n",
    "        if 'val' in line and 'byte loss' in line:\n",
    "            after_bl_str = line.split('byte loss')[1]\n",
    "            \n",
    "            try:                \n",
    "                byte_loss = float(after_bl_str.split(' ')[1])\n",
    "            except ValueError as e:\n",
    "                byte_loss = 100000\n",
    "            if byte_loss < best_loss_for_i:\n",
    "                best_loss_for_i = byte_loss\n",
    "                best_line = line\n",
    "    \n",
    "    if best_loss_for_i < 10000:\n",
    "        candidates.append((best_loss_for_i, i, best_line))\n",
    "candidates = sorted(candidates, key=lambda x: x[0])\n",
    "for e, f, l in candidates:\n",
    "    print(f.ljust(50), f'{e:.3} {l.strip()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(8192, 512)\n",
       "    (wpe): Embedding(256, 512)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=8192, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stuff = torch.load('logs/12l_32h_512d_8k_vocab_2e3_lr_good_max_eos/model_07891.pt')\n",
    "\n",
    "def remove_orig_mod_prefix(state_dict):\n",
    "    return {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "m = GPT(GPTConfig())\n",
    "m.load_state_dict(remove_orig_mod_prefix(all_stuff['model']))\n",
    "m.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'tiny-stories-8k-eos'\n",
    "enc = tokenizers.ByteLevelBPETokenizer(f'{data_dir}/tokenizer-vocab.json', f'{data_dir}/tokenizer-merges.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Lily went to the park and saw a friendly dog. She wanted to pet it. It was fluffy and brown. She saw the dog. Lily did not know that the dog was not a threatening to get caught. She asked her mom and dad about the catcher. They said hello at the same time.\n",
      "\n",
      "Lily was so happy. After a little while playing with her new friend. They hugged and the birds. They were very small but it was the perfect!\n",
      "Lily was so happy. When they saw the park every day. She went back home. One day, Max ran to the park. He saw his mommy and they were gone.\n",
      "\n",
      "Max didn't like this started to feel really sad. He felt much better. He didn't want to go home that day. He knew that his mom would never forget him.\n",
      "sample 1: Lily went to the park and saw a friendly dog. The dog was very big and had a big red crayon. She liked the dog, so she asked the dog if she could pet him too. But only for a little while. Lily was three years old. She had so much fun playing games around in the park. She ran and laughed, and ran around. She looked up at the birds. Finally, she was allowed to feed the animals. She was so happy. She smiled. She ate some of her own. After some time, she took some food. She was pleased to have a place to sit and enjoy the world.\n",
      "sample 2: Lily went to the park and saw a friendly dog. The dog at the park. The dog was a nice dog too. It was so cute! Lily and the dog met a nice lady. They said, \"Hello, this is your dog!\" Her mom smiled. They did the job. They saw the kids. They saw a big tree. In the end, Lily said, this is my way. This is my bear.\" They went to the park. But this time, we'll do something strange. We can talk. What do you want to do in our own us?\n",
      "\n",
      "Max said, \"But it's a surprise, he's the one? Why do you are so unhappy.\"\n",
      "\n",
      "Finally, the surprise brought joy to everyone and all to share. From that day on, Max and his friends enjoyed all the special moment together.\n",
      "sample 3: Lily went to the park and saw a friendly dog. She stopped and said, \"Hello, doggy, do you want to play in the park? What do you like so much, my little girl?\" The dog barked. Lily laughed and got the puppy. She took off the leash and her little puppy.\n",
      "\n",
      "As Lily was all ready to go to the big park. She smiled at the end. She was happy too. She knew she would have a great day. She hugged the pup and her parents!\n"
     ]
    }
   ],
   "source": [
    "generate(m, enc, \"Lily went to the park and saw a friendly dog.\", 255, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
