{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import GPTConfig, GPT, generate\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16l_16h_512d_hour_good_max                         0.31 step 31750 | val loss 1.2668 | byte loss 0.3097 | ds 3492.7s\n",
      "16l_16h_512d_hour                                  0.325 step 33523 | val loss 1.3311 | byte loss 0.3254 | ds 4448.7s\n",
      "16l_16h_512d_8_hour_good_max                       0.344 step 66750 | val loss 1.4055 | byte loss 0.3436 | ds 7307.2s\n",
      "16l_16h_512d_quick                                 0.85 step 499 | val loss 3.4753 | byte loss 0.8496 | ds 84.3s\n"
     ]
    }
   ],
   "source": [
    "def print_leaderboard_and_get_best_model():\n",
    "    candidates = []\n",
    "    for expt in os.listdir('logs'):\n",
    "        if 'smoke' in expt:\n",
    "            continue\n",
    "        best_loss_for_expt = 10000\n",
    "        best_line = ''\n",
    "\n",
    "        for line in open(f'logs/{expt}/log.txt').readlines():\n",
    "\n",
    "            if 'val' in line and 'byte loss' in line:\n",
    "                def get_byte_loss():\n",
    "                    after_bl_str = line.split('byte loss')[1]            \n",
    "                    try:                \n",
    "                        byte_loss = float(after_bl_str.split(' ')[1])\n",
    "                    except ValueError as e:\n",
    "                        byte_loss = 100000\n",
    "                    return byte_loss\n",
    "                \n",
    "                byte_loss = get_byte_loss()\n",
    "\n",
    "                if byte_loss < best_loss_for_expt:\n",
    "                    best_loss_for_expt = byte_loss\n",
    "                    best_line = line\n",
    "        \n",
    "        if best_loss_for_expt < 10000:\n",
    "            candidates.append((best_loss_for_expt, expt, best_line))\n",
    "\n",
    "    candidates = sorted(candidates, key=lambda x: x[0])\n",
    "    for best_loss, expt, line in candidates:\n",
    "        print(expt.ljust(50), f'{best_loss:.3} {line.strip()}')\n",
    "\n",
    "    best_expt = candidates[0][1]\n",
    "    best_model_paths = [model_path for model_path in os.listdir(f'logs/{best_expt}') if 'model' in model_path]\n",
    "    best_model_path = sorted(best_model_paths, key=lambda x: x.split('_')[1])[-1]\n",
    "    return best_expt, best_model_path\n",
    "\n",
    "best_expt, best_model_path = print_leaderboard_and_get_best_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(8192, 512)\n",
       "    (wpe): Embedding(512, 512)\n",
       "    (h): ModuleList(\n",
       "      (0-15): 16 x Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=8192, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choosen_model = f'logs/{best_expt}/{best_model_path}'\n",
    "# choosen_model = f'logs/16l_16h_512d_quick/model_00323.pt'\n",
    "full_checkpoint = torch.load(choosen_model)\n",
    "config = full_checkpoint['config']\n",
    "m = GPT(config)\n",
    "\n",
    "def remove_orig_mod_prefix(state_dict):\n",
    "    return {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "m.load_state_dict(remove_orig_mod_prefix(full_checkpoint['model']))\n",
    "m.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = AutoTokenizer.from_pretrained('activated-ai/tiny-stories-8k-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Lily went to the park and saw a friendly dog. The dog barked and Lily went to pet him. The dog's owner said, \"Do you want to ride my pony?\" Lily was so happy! She climbed on the pony and they rode around the park. But then, the pony suddenly stopped. Lily was scared and didn't know what to do. \n",
      "\n",
      "The owner said, \"Don't worry, I can reverse the pony. Can you hold the handle again?\" Lily held the handle and the horses started moving again. Lily was so happy and said, \"Thank you for your help, my pony is his best friend forever!\" They all went home and Lily told her mommy all about her pony ride.\n",
      "sample 1: Lily went to the park and saw a friendly dog. She gave the dog a hug and said, \"Hi, dog! What's your name?\"\n",
      "\n",
      "The dog wagged its tail and barked, \"Woof! My name is Max! Do you want to play with me?\" Lily and Max played, running and jumping in the grass. They had so much fun.\n",
      "\n",
      "Then, Lily remembered that she had to go home soon. She said goodbye to Max and ran home. When she got home, she told her mom about her fun day at the park. Lily was happy and hugged her mom.\n",
      "sample 2: Lily went to the park and saw a friendly dog. She wanted to play with the dog, but the dog was big and scary. Lily was scared and didn't want to go near the dog. She ran away and found her mommy on a bench. \n",
      "\n",
      "\"Mommy, the dog is scary,\" said Lily. \"I don't want to play with him.\" \n",
      "\n",
      "\"Don't worry, Lily,\" said her mommy. \"The dog is friendly. Come, let's go feed the dog.\" \n",
      "\n",
      "Lily slowly approached the dog and saw that he wanted a treat. She gave the dog the treat and he wagged his tail happily. From that day on, Lily wasn't scared of dogs anymore and they became friends.\n",
      "sample 3: Lily went to the park and saw a friendly dog. The dog was brown and fluffy. Lily loved dogs. She wanted to pet the dog, but the dog was too fast. The dog ran away and disappeared.\n",
      "\n",
      "Lily was sad that the dog left. \"Bye, doggy!\" she said. \"Don't disappear, doggy!\"\n"
     ]
    }
   ],
   "source": [
    "generate(m, enc, \"Lily went to the park and saw a friendly dog.\", 255, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
